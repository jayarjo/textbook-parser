# Textbook Parser: Illustrated Book Text Extraction & AI Summarization Pipeline

A comprehensive automated pipeline that extracts text and contextual meaning from illustrated book images to generate summaries, quizzes, and educational reports through Google Notebook integration.

## üéØ Overview

This system solves the challenge of extracting meaningful content from image-only book pages (e.g., from Google Drive, Calameo, or embedded viewers) with non-standard, illustration-heavy layouts. It combines:

- **Automated image retrieval** via browser automation
- **Intelligent layout analysis** to separate text from illustrations
- **High-accuracy OCR** optimized for Georgian and multilingual text
- **AI-powered illustration interpretation** using vision-language models
- **Google NotebookLM integration** for generating educational content

## üèóÔ∏è Architecture

```
Book URL ‚Üí Image Retriever (Playwright)
         ‚Üí Layout Analyzer (LayoutParser + Detectron2)
         ‚Üí Image Processor (Illustration Masking)
         ‚Üí OCR Engine (Tesseract/PaddleOCR)
         ‚Üí Illustration Interpreter (GPT-4V/Claude/Gemini)
         ‚Üí Google Notebook Integration
         ‚Üí Educational Content (Summaries, Quizzes, Audio)
```

## ‚ú® Features

- **Multi-source retrieval**: Works with Calameo, Google Drive, custom viewers
- **Layout-aware processing**: Intelligently separates text from images
- **Georgian language support**: Optimized for Georgian (·É•·Éê·É†·Éó·É£·Éö·Éò) text extraction
- **Vision AI integration**: Generates descriptions and educational context for illustrations
- **NotebookLM ready**: Exports content in formats compatible with Google NotebookLM
- **Modular architecture**: Run individual pipeline steps or the complete workflow
- **Configurable**: YAML-based configuration with sensible defaults

## üìã Prerequisites

### System Requirements

- Python 3.8+ OR Docker
- Tesseract OCR (for text extraction) - included in Docker image
- Playwright browsers (for web automation) - included in Docker image

### API Keys (Optional but Recommended)

- **OpenAI API key** (for GPT-4 Vision illustration interpretation)
- **Anthropic API key** (alternative: Claude with vision)
- **Google AI API key** (alternative: Gemini Pro Vision)

## üê≥ Docker (Recommended)

**Prefer Docker?** Skip the manual installation and use our Docker containers!

### Quick Start with Makefile (Easiest!)

```bash
# Build and start everything
make quick-start

# Process a book
make process URL="https://example.com/book" TITLE="My Book"

# View logs
make logs

# Stop services
make down
```

**üìñ See [MAKEFILE_GUIDE.md](MAKEFILE_GUIDE.md) for all Makefile commands**

### Quick Start with Scripts

```bash
# Build the container
./docker-build.sh single

# Run with your book URL
./docker-run.sh single --url "https://example.com/book" --title "My Book"

# Or use a configuration file
./docker-run.sh single --config config/example_georgian_book.yaml
```

### Docker Options

We provide **three deployment options**:

1. **Single Container** (recommended) - All-in-one, easy to use
   ```bash
   make build-single
   ./docker-run.sh single --url "https://example.com/book"
   ```

2. **Multi-Container** - Production setup with service isolation
   ```bash
   make build-multi
   make up-d
   make health
   ```

3. **GPU-Enabled** - Faster processing with GPU acceleration
   ```bash
   make build-gpu
   ./docker-run.sh gpu --config config/my_book.yaml
   ```

**üìñ See [DOCKER.md](DOCKER.md) for complete Docker documentation**
**üìñ See [API.md](API.md) for REST API documentation**
**üìñ See [QUICKSTART_API.md](QUICKSTART_API.md) for API quick start**

## üöÄ Installation (Manual)

### 1. Clone the Repository

```bash
git clone <repository-url>
cd textbook-parser
```

### 2. Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install Dependencies

```bash
pip install -r requirements.txt
```

### 4. Install Tesseract OCR

**Ubuntu/Debian:**
```bash
sudo apt-get install tesseract-ocr tesseract-ocr-kat tesseract-ocr-eng
```

**macOS:**
```bash
brew install tesseract tesseract-lang
```

**Windows:**
Download from: https://github.com/UB-Mannheim/tesseract/wiki

### 5. Install Playwright Browsers

```bash
playwright install chromium
```

### 6. Configure Environment Variables

```bash
cp .env.example .env
# Edit .env and add your API keys
```

## üìñ Usage

### Quick Start

Process a book from URL:

```bash
python main.py --url "https://example.com/book" --title "My Textbook"
```

### Using Configuration Files

```bash
python main.py --config config/example_georgian_book.yaml
```

### Run Specific Steps

```bash
# Only extract text (assumes images already retrieved)
python main.py --config config.yaml --step ocr --skip-retrieval

# Only interpret illustrations
python main.py --config config.yaml --step interpret
```

### Advanced Options

```bash
# Custom OCR engine and languages
python main.py --url "URL" --ocr-engine paddleocr --languages kat eng rus

# Skip illustration interpretation (faster)
python main.py --url "URL" --skip-interpretation

# Verbose logging
python main.py --url "URL" -v
```

## üìÅ Output Structure

```
output/
‚îú‚îÄ‚îÄ images/              # Retrieved book page images
‚îú‚îÄ‚îÄ cleaned/             # Images with illustrations masked (for OCR)
‚îú‚îÄ‚îÄ text/                # Extracted text files
‚îÇ   ‚îú‚îÄ‚îÄ page_001.txt
‚îÇ   ‚îú‚îÄ‚îÄ page_002.txt
‚îÇ   ‚îî‚îÄ‚îÄ book_full.txt    # Combined text
‚îú‚îÄ‚îÄ illustrations/       # Cropped illustration images
‚îú‚îÄ‚îÄ metadata/            # Analysis results
‚îÇ   ‚îú‚îÄ‚îÄ layout_analysis.json
‚îÇ   ‚îú‚îÄ‚îÄ ocr_metadata.json
‚îÇ   ‚îî‚îÄ‚îÄ illustration_descriptions.json
‚îú‚îÄ‚îÄ notebook_export/     # Google NotebookLM exports
‚îÇ   ‚îú‚îÄ‚îÄ notebook_source.md
‚îÇ   ‚îú‚îÄ‚îÄ study_guide.md
‚îÇ   ‚îî‚îÄ‚îÄ notebooklm_instructions.md
‚îî‚îÄ‚îÄ pipeline_summary.json
```

## üîß Configuration

### Configuration File Structure

See `config/default_config.yaml` for all available options:

```yaml
book_url: "https://example.com/book"
book_title: "My Textbook"
output_dir: "output"

retriever:
  headless: true
  timeout: 30000

layout_analyzer:
  model_name: "lp://PubLayNet/mask_rcnn_X_101_32x8d_FPN_3x/config"
  confidence_threshold: 0.5
  device: "cpu"

ocr:
  engine: "tesseract"
  languages: ["kat", "eng"]
  confidence_threshold: 60.0

illustration_interpreter:
  provider: "openai"
  model: "gpt-4-vision-preview"
```

### Environment Variables

```bash
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AIza...
```

## üéì Using with Google NotebookLM

After running the pipeline:

1. Navigate to `output/notebook_export/`
2. Upload `notebook_source.md` to [Google NotebookLM](https://notebooklm.google.com)
3. Use prompts like:
   - "Create a comprehensive summary of this textbook"
   - "Generate 20 multiple-choice questions"
   - "Generate an audio overview"

See `notebooklm_instructions.md` for detailed instructions.

## üîç Pipeline Modules

### 1. Image Retriever
- **Technology**: Playwright browser automation
- **Strategies**: Network interception, screenshots, direct download
- **Features**: Retry logic, lazy-load handling, rate limiting

### 2. Layout Analyzer
- **Technology**: LayoutParser + Detectron2
- **Detects**: Text blocks, illustrations, captions, titles, tables
- **Fallback**: Heuristic-based detection when models unavailable

### 3. Image Processor
- **Operations**: Illustration masking, cropping, enhancement
- **Features**: Deskewing, noise removal, contrast adjustment

### 4. OCR Engine
- **Engines**: Tesseract (default), PaddleOCR
- **Languages**: Georgian (kat), English (eng), Russian (rus), and more
- **Post-processing**: Text cleanup, hyphen removal, formatting

### 5. Illustration Interpreter
- **Providers**: OpenAI GPT-4V, Anthropic Claude, Google Gemini
- **Generates**: Captions, descriptions, tags, educational context
- **Context-aware**: Uses book metadata for better interpretation

### 6. Notebook Integration
- **Formats**: Markdown, JSON, structured text
- **Features**: Study guides, quiz prompts, summary templates
- **Compatible**: Google NotebookLM, general LLM tools

## üß™ Testing

Run individual modules:

```python
from src.ocr_engine import OCREngine
from pathlib import Path

ocr = OCREngine(engine="tesseract", languages=["kat", "eng"])
result = ocr.extract_text(Path("test_image.png"))
print(result.text)
```

## üõ†Ô∏è Troubleshooting

### Tesseract not found
```bash
# Set TESSERACT_CMD environment variable
export TESSERACT_CMD=/usr/local/bin/tesseract
```

### LayoutParser installation issues
```bash
# Install with specific PyTorch version
pip install torch==2.1.2 torchvision==0.16.2
pip install layoutparser[layoutmodels]
```

### Playwright browser issues
```bash
# Reinstall browsers
playwright install --force chromium
```

### Low OCR accuracy
- Ensure Georgian language pack is installed: `tesseract --list-langs`
- Try PaddleOCR: `--ocr-engine paddleocr`
- Adjust confidence threshold in config

## üìä Performance

| Books Processed | Pages | Time (avg) | Accuracy |
|----------------|-------|------------|----------|
| 10+ | 50-500 | 2-10 min | >90% OCR |

*Performance varies based on:*
- Network speed (for retrieval)
- Hardware (CPU vs GPU for layout analysis)
- Image quality
- Text complexity

## ü§ù Contributing

Contributions welcome! Areas for improvement:

- Additional OCR engine support
- Custom layout models for specific book types
- Enhanced Georgian text post-processing
- Direct Google NotebookLM API integration (when available)

## üìÑ License

MIT License - see LICENSE file

## üôè Acknowledgments

- [LayoutParser](https://layout-parser.github.io/) for document layout analysis
- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) for text extraction
- [Playwright](https://playwright.dev/) for browser automation
- [PaddleOCR](https://github.com/PaddlePaddle/PaddleOCR) for multilingual OCR

## üìß Support

For issues and questions:
- Create an issue on GitHub
- Check existing documentation
- Review example configurations

## üó∫Ô∏è Roadmap

- [ ] Direct Google NotebookLM API integration
- [ ] Web UI for easier usage
- [ ] Batch processing multiple books
- [ ] Custom fine-tuned layout models for Georgian texts
- [ ] Integration with Whisper for audio narration
- [ ] Semantic linking between text and illustrations
- [ ] Export to EPUB, Markdown, knowledge graphs
- [ ] Support for handwritten text recognition

---

**Built with ‚ù§Ô∏è for educational content extraction and AI-powered learning**
